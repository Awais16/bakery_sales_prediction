{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115b4ec2",
   "metadata": {},
   "source": [
    "#FINAL EXPORT (BEST MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b33b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "ROOT = Path(subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"]).decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32cc9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 13:19:16.120194: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-02 13:19:16.120677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 13:19:16.167094: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-02 13:19:18.132838: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 13:19:18.133284: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (7487, 18) (1841, 18) (1830, 18)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "2026-01-02 13:19:18.878610: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 70.9002 - mae: 164.6771 - val_loss: 44.3934 - val_mae: 104.0993\n",
      "Epoch 2/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 41.0484 - mae: 103.7458 - val_loss: 32.5494 - val_mae: 75.1254\n",
      "Epoch 3/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.5345 - mae: 70.0425 - val_loss: 24.4625 - val_mae: 50.8333\n",
      "Epoch 4/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.2084 - mae: 53.9299 - val_loss: 23.2631 - val_mae: 46.7879\n",
      "Epoch 5/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.7480 - mae: 50.1146 - val_loss: 22.4192 - val_mae: 44.7825\n",
      "Epoch 6/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 21.8594 - mae: 47.9386 - val_loss: 21.7893 - val_mae: 43.1021\n",
      "Epoch 7/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.2425 - mae: 46.3714 - val_loss: 21.2072 - val_mae: 41.6012\n",
      "Epoch 8/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.7423 - mae: 45.0254 - val_loss: 20.8086 - val_mae: 40.3950\n",
      "Epoch 9/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.3185 - mae: 43.9526 - val_loss: 20.5418 - val_mae: 39.4517\n",
      "Epoch 10/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.0167 - mae: 43.1238 - val_loss: 20.2994 - val_mae: 38.5037\n",
      "Epoch 11/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.7498 - mae: 42.4056 - val_loss: 20.2180 - val_mae: 37.9278\n",
      "Epoch 12/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5259 - mae: 41.6368 - val_loss: 20.0845 - val_mae: 37.2702\n",
      "Epoch 13/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3337 - mae: 41.0356 - val_loss: 19.9603 - val_mae: 36.6342\n",
      "Epoch 14/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1677 - mae: 40.3487 - val_loss: 19.8267 - val_mae: 36.1259\n",
      "Epoch 15/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0208 - mae: 39.8569 - val_loss: 19.7158 - val_mae: 35.6741\n",
      "Epoch 16/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8900 - mae: 39.3985 - val_loss: 19.6762 - val_mae: 35.3857\n",
      "Epoch 17/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7718 - mae: 38.9559 - val_loss: 19.5679 - val_mae: 35.0612\n",
      "Epoch 18/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6592 - mae: 38.5164 - val_loss: 19.5473 - val_mae: 34.8593\n",
      "Epoch 19/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5690 - mae: 38.2141 - val_loss: 19.4899 - val_mae: 34.5831\n",
      "Epoch 20/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.4685 - mae: 37.8644 - val_loss: 19.4364 - val_mae: 34.3271\n",
      "Epoch 21/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3961 - mae: 37.5671 - val_loss: 19.3529 - val_mae: 34.0452\n",
      "Epoch 22/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.3176 - mae: 37.2582 - val_loss: 19.3492 - val_mae: 33.8625\n",
      "Epoch 23/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2440 - mae: 36.9867 - val_loss: 19.3118 - val_mae: 33.8232\n",
      "Epoch 24/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1821 - mae: 36.7933 - val_loss: 19.2695 - val_mae: 33.6091\n",
      "Epoch 25/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1137 - mae: 36.5961 - val_loss: 19.2289 - val_mae: 33.4928\n",
      "Epoch 26/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.0767 - mae: 36.4655 - val_loss: 19.1839 - val_mae: 33.3763\n",
      "Epoch 27/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.0115 - mae: 36.2569 - val_loss: 19.1956 - val_mae: 33.3084\n",
      "Epoch 28/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9604 - mae: 36.1434 - val_loss: 19.1480 - val_mae: 33.1868\n",
      "Epoch 29/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.9194 - mae: 35.9854 - val_loss: 19.1511 - val_mae: 33.1457\n",
      "Epoch 30/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8803 - mae: 35.8547 - val_loss: 19.1381 - val_mae: 33.0557\n",
      "Epoch 31/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8475 - mae: 35.7765 - val_loss: 19.1649 - val_mae: 33.0330\n",
      "Epoch 32/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.8094 - mae: 35.6481 - val_loss: 19.1655 - val_mae: 33.0551\n",
      "Epoch 33/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7902 - mae: 35.5628 - val_loss: 19.1489 - val_mae: 32.9339\n",
      "Epoch 34/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7614 - mae: 35.4685 - val_loss: 19.1273 - val_mae: 32.8821\n",
      "Epoch 35/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7373 - mae: 35.3864 - val_loss: 19.0981 - val_mae: 32.8789\n",
      "Epoch 36/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7097 - mae: 35.3276 - val_loss: 19.1153 - val_mae: 32.8728\n",
      "Epoch 37/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6892 - mae: 35.2603 - val_loss: 19.1236 - val_mae: 32.8574\n",
      "Epoch 38/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6713 - mae: 35.2252 - val_loss: 19.0699 - val_mae: 32.7652\n",
      "Epoch 39/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6422 - mae: 35.1555 - val_loss: 19.0744 - val_mae: 32.8138\n",
      "Epoch 40/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6258 - mae: 35.0866 - val_loss: 19.0613 - val_mae: 32.7584\n",
      "Epoch 41/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6091 - mae: 35.0885 - val_loss: 19.0509 - val_mae: 32.6887\n",
      "Epoch 42/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5791 - mae: 34.9838 - val_loss: 19.0808 - val_mae: 32.7292\n",
      "Epoch 43/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5657 - mae: 34.9508 - val_loss: 19.0392 - val_mae: 32.6840\n",
      "Epoch 44/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5506 - mae: 34.9165 - val_loss: 19.0505 - val_mae: 32.6753\n",
      "Epoch 45/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5342 - mae: 34.8711 - val_loss: 19.0893 - val_mae: 32.7637\n",
      "Epoch 46/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5177 - mae: 34.8207 - val_loss: 18.9968 - val_mae: 32.6226\n",
      "Epoch 47/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4992 - mae: 34.7745 - val_loss: 19.0476 - val_mae: 32.6892\n",
      "Epoch 48/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4757 - mae: 34.7633 - val_loss: 19.0599 - val_mae: 32.6462\n",
      "Epoch 49/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4685 - mae: 34.7498 - val_loss: 19.0603 - val_mae: 32.6740\n",
      "Epoch 50/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4539 - mae: 34.7173 - val_loss: 19.0240 - val_mae: 32.6389\n",
      "Epoch 51/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4300 - mae: 34.6553 - val_loss: 19.0219 - val_mae: 32.6321\n",
      "Epoch 52/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4234 - mae: 34.6527 - val_loss: 19.0085 - val_mae: 32.6187\n",
      "Epoch 53/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4035 - mae: 34.6088 - val_loss: 19.0141 - val_mae: 32.6401\n",
      "Epoch 54/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3968 - mae: 34.5813 - val_loss: 18.9773 - val_mae: 32.5416\n",
      "Epoch 55/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3818 - mae: 34.5700 - val_loss: 19.0037 - val_mae: 32.6371\n",
      "Epoch 56/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3694 - mae: 34.5501 - val_loss: 18.9749 - val_mae: 32.5994\n",
      "Epoch 57/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3474 - mae: 34.5462 - val_loss: 18.9764 - val_mae: 32.5412\n",
      "Epoch 58/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.3446 - mae: 34.5149 - val_loss: 18.9607 - val_mae: 32.5023\n",
      "Epoch 59/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3325 - mae: 34.4814 - val_loss: 18.9261 - val_mae: 32.4773\n",
      "Epoch 60/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3197 - mae: 34.4845 - val_loss: 18.9967 - val_mae: 32.5178\n",
      "Epoch 61/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 17.3058 - mae: 34.4272 - val_loss: 18.9138 - val_mae: 32.4443\n",
      "Epoch 62/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3036 - mae: 34.4395 - val_loss: 18.8785 - val_mae: 32.3585\n",
      "Epoch 63/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2942 - mae: 34.4440 - val_loss: 18.9241 - val_mae: 32.4362\n",
      "Epoch 64/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.2796 - mae: 34.3975 - val_loss: 18.8958 - val_mae: 32.3914\n",
      "Epoch 65/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2650 - mae: 34.3792 - val_loss: 18.9240 - val_mae: 32.3627\n",
      "Epoch 66/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2535 - mae: 34.3536 - val_loss: 18.8707 - val_mae: 32.3647\n",
      "Epoch 67/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2471 - mae: 34.3559 - val_loss: 18.9156 - val_mae: 32.4506\n",
      "Epoch 68/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2369 - mae: 34.3289 - val_loss: 18.8896 - val_mae: 32.3425\n",
      "Epoch 69/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2281 - mae: 34.3025 - val_loss: 18.9015 - val_mae: 32.3580\n",
      "Epoch 70/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2088 - mae: 34.2811 - val_loss: 18.9253 - val_mae: 32.3137\n",
      "Epoch 71/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2154 - mae: 34.3020 - val_loss: 18.9231 - val_mae: 32.4346\n",
      "Epoch 72/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2113 - mae: 34.2918 - val_loss: 18.8613 - val_mae: 32.3189\n",
      "Epoch 73/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.1889 - mae: 34.2598 - val_loss: 18.8662 - val_mae: 32.3041\n",
      "Epoch 74/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1883 - mae: 34.2536 - val_loss: 18.8594 - val_mae: 32.3014\n",
      "Epoch 75/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1727 - mae: 34.2493 - val_loss: 18.8754 - val_mae: 32.3474\n",
      "Epoch 76/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1681 - mae: 34.2256 - val_loss: 18.8566 - val_mae: 32.3053\n",
      "Epoch 77/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1669 - mae: 34.2047 - val_loss: 18.8585 - val_mae: 32.2471\n",
      "Epoch 78/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1599 - mae: 34.1990 - val_loss: 18.8234 - val_mae: 32.2303\n",
      "Epoch 79/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1535 - mae: 34.2183 - val_loss: 18.8431 - val_mae: 32.2366\n",
      "Epoch 80/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1321 - mae: 34.1491 - val_loss: 18.8970 - val_mae: 32.2865\n",
      "Epoch 81/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1164 - mae: 34.1328 - val_loss: 18.8540 - val_mae: 32.2401\n",
      "Epoch 82/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1288 - mae: 34.1493 - val_loss: 18.8833 - val_mae: 32.2998\n",
      "Epoch 83/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1013 - mae: 34.1046 - val_loss: 18.9254 - val_mae: 32.3492\n",
      "Epoch 84/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1020 - mae: 34.0905 - val_loss: 18.8933 - val_mae: 32.2147\n",
      "Epoch 85/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0934 - mae: 34.0825 - val_loss: 18.9140 - val_mae: 32.2476\n",
      "Epoch 86/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.0822 - mae: 34.0507 - val_loss: 18.8791 - val_mae: 32.1754\n",
      "Epoch 87/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0697 - mae: 34.0600 - val_loss: 18.8937 - val_mae: 32.2567\n",
      "Epoch 88/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0717 - mae: 34.0273 - val_loss: 18.9065 - val_mae: 32.2153\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Validation MAPE %: 18.82\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Saved: /workspaces/bakery_sales_prediction/data/processed/submission_nn_best.csv\n",
      "rows: 1830\n",
      "pred mean/min/max: 192.76564025878906 30.908065795898438 691.0988159179688\n",
      "        id      umsatz\n",
      "0  1808011  135.388992\n",
      "1  1808012  555.867493\n",
      "2  1808013  274.673676\n",
      "3  1808014   68.098389\n",
      "4  1808015  295.514282\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # FINAL EXPORT (BEST MODEL) — NN baseline without rolling7 (Kaggle ~0.19488)\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1) Load data\n",
    "\n",
    "\n",
    "train_path = ROOT / \"data\" / \"processed\" / \"df_train_data_cleaned.csv\"\n",
    "val_path   = ROOT / \"data\" / \"processed\" / \"df_validation_data_cleaned.csv\"\n",
    "test_path  = ROOT / \"data\" / \"processed\" / \"df_test_data_cleaned.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val   = pd.read_csv(val_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "for df in (df_train, df_val, df_test):\n",
    "    df[\"Datum\"] = pd.to_datetime(df[\"Datum\"], errors=\"coerce\")\n",
    "\n",
    "target = \"Umsatz_umsatz\"\n",
    "\n",
    "# 2) Split X/y\n",
    "X_train = df_train.drop(columns=[target, \"Datum\"])\n",
    "y_train = df_train[target].astype(float)\n",
    "\n",
    "X_val = df_val.drop(columns=[target, \"Datum\"])\n",
    "y_val = df_val[target].astype(float)\n",
    "\n",
    "# test has no target\n",
    "X_test = df_test.drop(columns=[\"Datum\"])\n",
    "\n",
    "# 3) Drop rolling7 (best model)\n",
    "drop_cols = [\"umsatz_rolling7\"]\n",
    "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_val   = X_val.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_test  = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# 4) Ensure categorical as string\n",
    "cat_cols = [\"Warengruppe_umsatz\"]\n",
    "for df in (X_train, X_val, X_test):\n",
    "    df[\"Warengruppe_umsatz\"] = df[\"Warengruppe_umsatz\"].astype(int).astype(str)\n",
    "\n",
    "# 5) Align columns (very important)\n",
    "# make sure val/test have exactly same feature columns as train\n",
    "X_val  = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# 6) Preprocess (scaling + one-hot)\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_p = preprocess.fit_transform(X_train)\n",
    "X_val_p   = preprocess.transform(X_val)\n",
    "X_test_p  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Shapes:\", X_train_p.shape, X_val_p.shape, X_test_p.shape)\n",
    "\n",
    "# 7) Build + train NN (same architecture)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_p.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mape\",                 # to match Kaggle metric\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_p, y_train,\n",
    "    validation_data=(X_val_p, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# quick sanity check on val (MAPE)\n",
    "pred_val = model.predict(X_val_p).ravel()\n",
    "pred_val = np.clip(pred_val, 0, None)\n",
    "val_mape = mean_absolute_percentage_error(y_val, pred_val) * 100\n",
    "print(f\"Validation MAPE %: {val_mape:.2f}\")\n",
    "\n",
    "# 8) Predict test + create submission\n",
    "pred_test = model.predict(X_test_p).ravel()\n",
    "pred_test = np.clip(pred_test, 0, None)\n",
    "\n",
    "submission = df_test[[\"id\"]].copy()\n",
    "submission[\"umsatz\"] = pred_test\n",
    "\n",
    "out_path   = ROOT / \"data\" / \"processed\" / \"submission_nn_best.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"rows:\", len(submission))\n",
    "print(\"pred mean/min/max:\",\n",
    "      float(submission[\"umsatz\"].mean()),\n",
    "      float(submission[\"umsatz\"].min()),\n",
    "      float(submission[\"umsatz\"].max()))\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad55767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train min/max: 12.9373828412174 1879.46183076734\n",
      "pred_val min/max: 22.379587 686.88116\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train min/max:\", y_train.min(), y_train.max())\n",
    "print(\"pred_val min/max:\", pred_val.min(), pred_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e985176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE %: 18.82\n",
      "Validation RMSE : 52.12\n",
      "Validation R2   : 0.8395\n",
      "Validation MAE  : 32.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# predictions already computed: pred_val\n",
    "rmse = np.sqrt(mean_squared_error(y_val, pred_val))\n",
    "r2   = r2_score(y_val, pred_val)\n",
    "mae  = mean_absolute_error(y_val, pred_val)\n",
    "\n",
    "print(f\"Validation MAPE %: {val_mape:.2f}\")\n",
    "print(f\"Validation RMSE : {rmse:.2f}\")\n",
    "print(f\"Validation R2   : {r2:.4f}\")\n",
    "print(f\"Validation MAE  : {mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b7bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
