{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115b4ec2",
   "metadata": {},
   "source": [
    "#FINAL EXPORT (BEST MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b33b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "ROOT = Path(subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"]).decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cc9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (7487, 18) (1841, 18) (1830, 18)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 11:49:25.719478: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 75.7710 - mae: 172.6764 - val_loss: 46.7604 - val_mae: 107.7386\n",
      "Epoch 2/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.5711 - mae: 107.6000 - val_loss: 34.2592 - val_mae: 79.3066\n",
      "Epoch 3/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.7037 - mae: 73.9372 - val_loss: 24.9345 - val_mae: 51.9840\n",
      "Epoch 4/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.5212 - mae: 55.0842 - val_loss: 23.7149 - val_mae: 47.7035\n",
      "Epoch 5/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.9914 - mae: 50.5846 - val_loss: 22.7706 - val_mae: 45.3726\n",
      "Epoch 6/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.0775 - mae: 48.3991 - val_loss: 22.1402 - val_mae: 43.9175\n",
      "Epoch 7/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.4311 - mae: 46.7888 - val_loss: 21.5769 - val_mae: 42.3852\n",
      "Epoch 8/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.9240 - mae: 45.4938 - val_loss: 21.1450 - val_mae: 41.3854\n",
      "Epoch 9/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5368 - mae: 44.6239 - val_loss: 20.8031 - val_mae: 40.2019\n",
      "Epoch 10/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2084 - mae: 43.7109 - val_loss: 20.5547 - val_mae: 39.3998\n",
      "Epoch 11/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9294 - mae: 42.9772 - val_loss: 20.3964 - val_mae: 38.9301\n",
      "Epoch 12/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.6962 - mae: 42.3087 - val_loss: 20.2541 - val_mae: 38.1985\n",
      "Epoch 13/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4823 - mae: 41.5870 - val_loss: 20.1118 - val_mae: 37.5727\n",
      "Epoch 14/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2829 - mae: 40.9757 - val_loss: 19.9672 - val_mae: 37.1019\n",
      "Epoch 15/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1036 - mae: 40.3253 - val_loss: 19.8310 - val_mae: 36.5014\n",
      "Epoch 16/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9217 - mae: 39.6670 - val_loss: 19.6935 - val_mae: 36.0217\n",
      "Epoch 17/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 18.7592 - mae: 39.1039 - val_loss: 19.6076 - val_mae: 35.5449\n",
      "Epoch 18/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 18.6093 - mae: 38.6322 - val_loss: 19.5083 - val_mae: 35.1312\n",
      "Epoch 19/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.4903 - mae: 38.2034 - val_loss: 19.4179 - val_mae: 34.8017\n",
      "Epoch 20/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3798 - mae: 37.7944 - val_loss: 19.4340 - val_mae: 34.6722\n",
      "Epoch 21/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2849 - mae: 37.4394 - val_loss: 19.4164 - val_mae: 34.3566\n",
      "Epoch 22/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2014 - mae: 37.1031 - val_loss: 19.2845 - val_mae: 34.1358\n",
      "Epoch 23/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1234 - mae: 36.8024 - val_loss: 19.2955 - val_mae: 33.9644\n",
      "Epoch 24/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.0575 - mae: 36.5740 - val_loss: 19.2743 - val_mae: 33.8474\n",
      "Epoch 25/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9991 - mae: 36.3706 - val_loss: 19.2628 - val_mae: 33.7145\n",
      "Epoch 26/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9486 - mae: 36.1846 - val_loss: 19.1484 - val_mae: 33.5356\n",
      "Epoch 27/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9014 - mae: 35.9963 - val_loss: 19.2025 - val_mae: 33.4755\n",
      "Epoch 28/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8541 - mae: 35.8761 - val_loss: 19.1609 - val_mae: 33.3845\n",
      "Epoch 29/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8199 - mae: 35.8037 - val_loss: 19.1817 - val_mae: 33.3850\n",
      "Epoch 30/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7876 - mae: 35.6847 - val_loss: 19.1990 - val_mae: 33.3209\n",
      "Epoch 31/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7596 - mae: 35.5751 - val_loss: 19.2247 - val_mae: 33.4042\n",
      "Epoch 32/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7414 - mae: 35.4927 - val_loss: 19.2318 - val_mae: 33.3546\n",
      "Epoch 33/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7037 - mae: 35.4277 - val_loss: 19.1874 - val_mae: 33.1931\n",
      "Epoch 34/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.6846 - mae: 35.3389 - val_loss: 19.1706 - val_mae: 33.2259\n",
      "Epoch 35/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6483 - mae: 35.2423 - val_loss: 19.1998 - val_mae: 33.1967\n",
      "Epoch 36/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6269 - mae: 35.1826 - val_loss: 19.1292 - val_mae: 33.1216\n",
      "Epoch 37/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17.6127 - mae: 35.1287 - val_loss: 19.1546 - val_mae: 33.0778\n",
      "Epoch 38/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 17.5902 - mae: 35.0609 - val_loss: 19.1976 - val_mae: 33.0957\n",
      "Epoch 39/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5663 - mae: 35.0224 - val_loss: 19.1230 - val_mae: 32.9960\n",
      "Epoch 40/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5412 - mae: 34.9651 - val_loss: 19.1535 - val_mae: 33.0334\n",
      "Epoch 41/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5316 - mae: 34.9213 - val_loss: 19.0873 - val_mae: 32.9604\n",
      "Epoch 42/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5122 - mae: 34.8712 - val_loss: 19.0948 - val_mae: 32.9853\n",
      "Epoch 43/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4968 - mae: 34.8341 - val_loss: 19.0462 - val_mae: 32.9276\n",
      "Epoch 44/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4773 - mae: 34.7994 - val_loss: 19.1383 - val_mae: 32.9384\n",
      "Epoch 45/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4662 - mae: 34.7883 - val_loss: 19.0907 - val_mae: 32.8924\n",
      "Epoch 46/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4596 - mae: 34.7403 - val_loss: 19.1315 - val_mae: 32.9829\n",
      "Epoch 47/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4293 - mae: 34.7008 - val_loss: 19.1095 - val_mae: 33.0146\n",
      "Epoch 48/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4149 - mae: 34.6601 - val_loss: 19.0993 - val_mae: 32.9695\n",
      "Epoch 49/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4047 - mae: 34.6571 - val_loss: 19.0875 - val_mae: 32.9606\n",
      "Epoch 50/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3864 - mae: 34.6370 - val_loss: 19.1237 - val_mae: 32.9893\n",
      "Epoch 51/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3858 - mae: 34.5939 - val_loss: 19.1108 - val_mae: 32.9339\n",
      "Epoch 52/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3634 - mae: 34.5865 - val_loss: 19.0783 - val_mae: 32.9491\n",
      "Epoch 53/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3519 - mae: 34.5501 - val_loss: 19.1086 - val_mae: 32.9260\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Validation MAPE %: 19.05\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step\n",
      "Saved: /workspaces/bakery_sales_prediction/data/processed/submission_nn_best.csv\n",
      "rows: 1830\n",
      "pred mean/min/max: 193.56033325195312 24.63062286376953 662.0006103515625\n",
      "        id      umsatz\n",
      "0  1808011  139.556381\n",
      "1  1808012  550.018250\n",
      "2  1808013  266.397461\n",
      "3  1808014   67.649673\n",
      "4  1808015  304.082886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # FINAL EXPORT (BEST MODEL) — NN baseline without rolling7 (Kaggle ~0.19488)\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1) Load data\n",
    "\n",
    "\n",
    "train_path = ROOT / \"data\" / \"processed\" / \"df_train_data_cleaned.csv\"\n",
    "val_path   = ROOT / \"data\" / \"processed\" / \"df_validation_data_cleaned.csv\"\n",
    "test_path  = ROOT / \"data\" / \"processed\" / \"df_test_data_cleaned.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val   = pd.read_csv(val_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "for df in (df_train, df_val, df_test):\n",
    "    df[\"Datum\"] = pd.to_datetime(df[\"Datum\"], errors=\"coerce\")\n",
    "\n",
    "target = \"Umsatz_umsatz\"\n",
    "\n",
    "# 2) Split X/y\n",
    "X_train = df_train.drop(columns=[target, \"Datum\"])\n",
    "y_train = df_train[target].astype(float)\n",
    "\n",
    "X_val = df_val.drop(columns=[target, \"Datum\"])\n",
    "y_val = df_val[target].astype(float)\n",
    "\n",
    "# test has no target\n",
    "X_test = df_test.drop(columns=[\"Datum\"])\n",
    "\n",
    "# 3) Drop rolling7 (best model)\n",
    "drop_cols = [\"umsatz_rolling7\"]\n",
    "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_val   = X_val.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_test  = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# 4) Ensure categorical as string\n",
    "cat_cols = [\"Warengruppe_umsatz\"]\n",
    "for df in (X_train, X_val, X_test):\n",
    "    df[\"Warengruppe_umsatz\"] = df[\"Warengruppe_umsatz\"].astype(int).astype(str)\n",
    "\n",
    "# 5) Align columns (very important)\n",
    "# make sure val/test have exactly same feature columns as train\n",
    "X_val  = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# 6) Preprocess (scaling + one-hot)\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_p = preprocess.fit_transform(X_train)\n",
    "X_val_p   = preprocess.transform(X_val)\n",
    "X_test_p  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Shapes:\", X_train_p.shape, X_val_p.shape, X_test_p.shape)\n",
    "\n",
    "# 7) Build + train NN (same architecture)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_p.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mape\",                 # to match Kaggle metric\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_p, y_train,\n",
    "    validation_data=(X_val_p, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# quick sanity check on val (MAPE)\n",
    "pred_val = model.predict(X_val_p).ravel()\n",
    "pred_val = np.clip(pred_val, 0, None)\n",
    "val_mape = mean_absolute_percentage_error(y_val, pred_val) * 100\n",
    "print(f\"Validation MAPE %: {val_mape:.2f}\")\n",
    "\n",
    "# 8) Predict test + create submission\n",
    "pred_test = model.predict(X_test_p).ravel()\n",
    "pred_test = np.clip(pred_test, 0, None)\n",
    "\n",
    "submission = df_test[[\"id\"]].copy()\n",
    "submission[\"umsatz\"] = pred_test\n",
    "\n",
    "out_path   = ROOT / \"data\" / \"processed\" / \"submission_nn_best.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"rows:\", len(submission))\n",
    "print(\"pred mean/min/max:\",\n",
    "      float(submission[\"umsatz\"].mean()),\n",
    "      float(submission[\"umsatz\"].min()),\n",
    "      float(submission[\"umsatz\"].max()))\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad55767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train min/max: 12.9373828412174 1879.46183076734\n",
      "pred_val min/max: 22.423714 659.35956\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train min/max:\", y_train.min(), y_train.max())\n",
    "print(\"pred_val min/max:\", pred_val.min(), pred_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985176c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
