{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115b4ec2",
   "metadata": {},
   "source": [
    "#FINAL EXPORT (BEST MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b33b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "ROOT = Path(subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"]).decode().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32cc9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 14:27:42.917674: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-02 14:27:42.918032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 14:27:42.965567: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-02 14:27:45.346865: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-02 14:27:45.347477: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (7487, 18) (1841, 18) (1830, 18)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "2026-01-02 14:27:46.216315: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 73.6218 - mae: 169.0532 - val_loss: 46.3034 - val_mae: 105.8230\n",
      "Epoch 2/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 42.3880 - mae: 106.4514 - val_loss: 34.1122 - val_mae: 78.4408\n",
      "Epoch 3/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.0109 - mae: 74.2098 - val_loss: 25.1870 - val_mae: 52.5322\n",
      "Epoch 4/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 24.8844 - mae: 55.6761 - val_loss: 23.8875 - val_mae: 47.9643\n",
      "Epoch 5/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.2080 - mae: 50.8735 - val_loss: 22.8551 - val_mae: 45.4778\n",
      "Epoch 6/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.2325 - mae: 48.3919 - val_loss: 22.1519 - val_mae: 43.7610\n",
      "Epoch 7/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.5184 - mae: 46.8993 - val_loss: 21.5261 - val_mae: 42.3952\n",
      "Epoch 8/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.9697 - mae: 45.5260 - val_loss: 21.0482 - val_mae: 41.0348\n",
      "Epoch 9/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5398 - mae: 44.5515 - val_loss: 20.7055 - val_mae: 40.1100\n",
      "Epoch 10/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1923 - mae: 43.7552 - val_loss: 20.4822 - val_mae: 39.2951\n",
      "Epoch 11/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9105 - mae: 42.9473 - val_loss: 20.2806 - val_mae: 38.5448\n",
      "Epoch 12/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6777 - mae: 42.2174 - val_loss: 20.1202 - val_mae: 37.8491\n",
      "Epoch 13/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4736 - mae: 41.5267 - val_loss: 20.0134 - val_mae: 37.3081\n",
      "Epoch 14/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2969 - mae: 40.9318 - val_loss: 19.9451 - val_mae: 36.7903\n",
      "Epoch 15/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1479 - mae: 40.3878 - val_loss: 19.8180 - val_mae: 36.4371\n",
      "Epoch 16/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9939 - mae: 39.8653 - val_loss: 19.6757 - val_mae: 35.8820\n",
      "Epoch 17/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8398 - mae: 39.3825 - val_loss: 19.5528 - val_mae: 35.6396\n",
      "Epoch 18/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7127 - mae: 38.9087 - val_loss: 19.5132 - val_mae: 35.3228\n",
      "Epoch 19/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6055 - mae: 38.5097 - val_loss: 19.3750 - val_mae: 34.9693\n",
      "Epoch 20/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.4995 - mae: 38.1365 - val_loss: 19.3153 - val_mae: 34.6699\n",
      "Epoch 21/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.4017 - mae: 37.8208 - val_loss: 19.2838 - val_mae: 34.5252\n",
      "Epoch 22/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3089 - mae: 37.5217 - val_loss: 19.3043 - val_mae: 34.3767\n",
      "Epoch 23/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2191 - mae: 37.2060 - val_loss: 19.2093 - val_mae: 34.0432\n",
      "Epoch 24/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1415 - mae: 36.9283 - val_loss: 19.1891 - val_mae: 33.9076\n",
      "Epoch 25/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.0824 - mae: 36.7285 - val_loss: 19.1969 - val_mae: 33.7887\n",
      "Epoch 26/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.0254 - mae: 36.4656 - val_loss: 19.2131 - val_mae: 33.6927\n",
      "Epoch 27/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9711 - mae: 36.2416 - val_loss: 19.1747 - val_mae: 33.5359\n",
      "Epoch 28/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.9140 - mae: 36.1026 - val_loss: 19.1373 - val_mae: 33.4598\n",
      "Epoch 29/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8587 - mae: 35.9170 - val_loss: 19.0394 - val_mae: 33.3077\n",
      "Epoch 30/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8063 - mae: 35.7877 - val_loss: 19.0466 - val_mae: 33.2389\n",
      "Epoch 31/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7780 - mae: 35.6610 - val_loss: 19.1072 - val_mae: 33.2310\n",
      "Epoch 32/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7369 - mae: 35.5323 - val_loss: 19.0265 - val_mae: 33.0997\n",
      "Epoch 33/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7198 - mae: 35.5112 - val_loss: 19.0727 - val_mae: 33.1545\n",
      "Epoch 34/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6820 - mae: 35.3736 - val_loss: 19.0343 - val_mae: 33.0912\n",
      "Epoch 35/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6679 - mae: 35.3302 - val_loss: 19.0520 - val_mae: 33.1029\n",
      "Epoch 36/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6367 - mae: 35.2494 - val_loss: 18.9900 - val_mae: 32.9478\n",
      "Epoch 37/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5969 - mae: 35.1428 - val_loss: 19.0617 - val_mae: 33.0016\n",
      "Epoch 38/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5878 - mae: 35.0936 - val_loss: 19.0586 - val_mae: 33.0149\n",
      "Epoch 39/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5584 - mae: 35.0166 - val_loss: 19.0628 - val_mae: 33.0139\n",
      "Epoch 40/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5481 - mae: 35.0083 - val_loss: 19.0655 - val_mae: 33.0126\n",
      "Epoch 41/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.5299 - mae: 34.9504 - val_loss: 19.1025 - val_mae: 33.0654\n",
      "Epoch 42/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.4935 - mae: 34.8487 - val_loss: 19.0840 - val_mae: 33.0136\n",
      "Epoch 43/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4975 - mae: 34.8317 - val_loss: 19.0791 - val_mae: 32.9283\n",
      "Epoch 44/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4670 - mae: 34.7742 - val_loss: 19.0353 - val_mae: 32.9182\n",
      "Epoch 45/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4520 - mae: 34.7549 - val_loss: 19.0419 - val_mae: 32.9347\n",
      "Epoch 46/200\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4289 - mae: 34.7063 - val_loss: 19.0387 - val_mae: 32.8788\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Validation MAPE %: 18.99\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step\n",
      "Saved: /workspaces/bakery_sales_prediction/data/processed/submission_nn_best.csv\n",
      "rows: 1830\n",
      "pred mean/min/max: 193.00096130371094 27.43558120727539 642.9237060546875\n",
      "        id      umsatz\n",
      "0  1808011  139.191864\n",
      "1  1808012  531.929077\n",
      "2  1808013  263.850128\n",
      "3  1808014   70.214035\n",
      "4  1808015  310.645782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # FINAL EXPORT (BEST MODEL) — NN baseline without rolling7 (Kaggle ~0.19488)\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1) Load data\n",
    "\n",
    "\n",
    "train_path = ROOT / \"data\" / \"processed\" / \"df_train_data_cleaned.csv\"\n",
    "val_path   = ROOT / \"data\" / \"processed\" / \"df_validation_data_cleaned.csv\"\n",
    "test_path  = ROOT / \"data\" / \"processed\" / \"df_test_data_cleaned.csv\"\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val   = pd.read_csv(val_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "for df in (df_train, df_val, df_test):\n",
    "    df[\"Datum\"] = pd.to_datetime(df[\"Datum\"], errors=\"coerce\")\n",
    "\n",
    "target = \"Umsatz_umsatz\"\n",
    "\n",
    "# 2) Split X/y\n",
    "X_train = df_train.drop(columns=[target, \"Datum\"])\n",
    "y_train = df_train[target].astype(float)\n",
    "\n",
    "X_val = df_val.drop(columns=[target, \"Datum\"])\n",
    "y_val = df_val[target].astype(float)\n",
    "\n",
    "# test has no target\n",
    "X_test = df_test.drop(columns=[\"Datum\"])\n",
    "\n",
    "# 3) Drop rolling7 (best model)\n",
    "drop_cols = [\"umsatz_rolling7\"]\n",
    "X_train = X_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_val   = X_val.drop(columns=drop_cols, errors=\"ignore\")\n",
    "X_test  = X_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# 4) Ensure categorical as string\n",
    "cat_cols = [\"Warengruppe_umsatz\"]\n",
    "for df in (X_train, X_val, X_test):\n",
    "    df[\"Warengruppe_umsatz\"] = df[\"Warengruppe_umsatz\"].astype(int).astype(str)\n",
    "\n",
    "# 5) Align columns (very important)\n",
    "# make sure val/test have exactly same feature columns as train\n",
    "X_val  = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# 6) Preprocess (scaling + one-hot)\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_p = preprocess.fit_transform(X_train)\n",
    "X_val_p   = preprocess.transform(X_val)\n",
    "X_test_p  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Shapes:\", X_train_p.shape, X_val_p.shape, X_test_p.shape)\n",
    "\n",
    "# 7) Build + train NN (same architecture)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_p.shape[1],)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"mape\",                 # to match Kaggle metric\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_p, y_train,\n",
    "    validation_data=(X_val_p, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# quick sanity check on val (MAPE)\n",
    "pred_val = model.predict(X_val_p).ravel()\n",
    "pred_val = np.clip(pred_val, 0, None)\n",
    "val_mape = mean_absolute_percentage_error(y_val, pred_val) * 100\n",
    "print(f\"Validation MAPE %: {val_mape:.2f}\")\n",
    "\n",
    "# 8) Predict test + create submission\n",
    "pred_test = model.predict(X_test_p).ravel()\n",
    "pred_test = np.clip(pred_test, 0, None)\n",
    "\n",
    "submission = df_test[[\"id\"]].copy()\n",
    "submission[\"umsatz\"] = pred_test\n",
    "\n",
    "out_path   = ROOT / \"data\" / \"processed\" / \"submission_nn_best.csv\"\n",
    "submission.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"rows:\", len(submission))\n",
    "print(\"pred mean/min/max:\",\n",
    "      float(submission[\"umsatz\"].mean()),\n",
    "      float(submission[\"umsatz\"].min()),\n",
    "      float(submission[\"umsatz\"].max()))\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad55767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train min/max: 12.9373828412174 1879.46183076734\n",
      "pred_val min/max: 23.748226 638.7128\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train min/max:\", y_train.min(), y_train.max())\n",
    "print(\"pred_val min/max:\", pred_val.min(), pred_val.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e985176c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAPE %: 18.99\n",
      "Validation RMSE : 52.71\n",
      "Validation R2   : 0.8358\n",
      "Validation MAE  : 32.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# predictions already computed: pred_val\n",
    "rmse = np.sqrt(mean_squared_error(y_val, pred_val))\n",
    "r2   = r2_score(y_val, pred_val)\n",
    "mae  = mean_absolute_error(y_val, pred_val)\n",
    "\n",
    "print(f\"Validation MAPE %: {val_mape:.2f}\")\n",
    "print(f\"Validation RMSE : {rmse:.2f}\")\n",
    "print(f\"Validation R2   : {r2:.4f}\")\n",
    "print(f\"Validation MAE  : {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c379c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
